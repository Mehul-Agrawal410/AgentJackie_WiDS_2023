# AgentJackie_WiDS_2023

Welcome to the repository showcasing my journey in the WiDS '23 program, where I explored the realms of reinforcement learning through a captivating project. The primary focus was on training a reinforcement learning model to master the game "Kung Fu Master" in the OpenAI Gym environment. You can find the project details [here](https://github.com/Nahush-27/Agent-Jackie-Reinforcement-Learning-Adventures-in-Kung-Fu.git).

## Week 1:
The inaugural week laid the foundation, covering essential aspects of Python, machine learning, and reinforcement learning. It introduced key libraries such as NumPy, Pandas, and Matplotlib. In the [Week 1 assignment](https://github.com/Mehul-Agrawal410/AgentJackie_WiDS_2023/blob/main/Week_1.ipynb), we implemented a linear regression model from scratch, tested it on a mentor-provided dataset, and delved into the basics of machine learning.

**Resources**:
- [Supervised Learning: Regression & Classification - Coursera](https://www.coursera.org/learn/machine-learning/home/week/1)
- [Supervised Learning: Regression & Classification - Coursera Week 3](https://www.coursera.org/learn/machine-learning/home/week/3)

## Week 2:
This week marked our introduction to reinforcement learning and the exploration of the multi-armed bandit problem. The assignment ([Week 2.ipynb](https://github.com/Mehul-Agrawal410/AgentJackie_WiDS_2023/blob/main/Week_2.ipynb)) tasked us with implementing algorithms like Epsilon Greedy, UCB, and Thompson Sampling to solve the multi-armed bandit problem. Through comprehensive exploration, I determined that Thompson Sampling emerged as the most effective algorithm.

**Resources**:
- [Multi-Armed Bandit](https://gibberblot.github.io/rl-notes/single-agent/multi-armed-bandits.html)
- [Introductory Video](https://youtu.be/9pZv3-6EUq8?feature=shared)
- [Epsilon Greedy Algorithm](https://youtu.be/EjYEsbg95x0?feature=shared)
- [Thompson Sampling Algorithm](https://youtu.be/GVQUGNv33LY?feature=shared)
- [Upper Confidence Bound (UCB) Algorithm](https://youtu.be/s6UHInwoqb0?feature=shared)
- [Thompson vs UCB](https://youtu.be/e4f0or7x5xc?feature=shared)

## Week 3:
This week delved deeper into reinforcement learning, focusing on Markov Decision Processes (MDPs) and the Value Iteration algorithm. The [Week 3 assignment](https://github.com/Mehul-Agrawal410/AgentJackie_WiDS_2023/blob/main/Week_3.ipynb) tasked us with planning an MDP using the Value Iteration algorithm to achieve optimality for the given MDP.

**Resources**:
- [Markov Decision Problem Part 1](https://towardsdatascience.com/introduction-to-reinforcement-learning-markov-decision-process-44c533ebf8da)
- [Markov Decision Problem Part 2](https://towardsdatascience.com/introduction-to-reinforcement-learning-markov-decision-process-44c533ebf8da)
- [Alternate Slides for MDP](https://www.davidsilver.uk/wp-content/uploads/2020/03/MDP.pdf)
- [Solving MDP](https://web.mit.edu/1.041/www/fall2021/www/lectures/L15-value-iteration-2021fa-pre.pdf)

## Week 4-5 and Final Project:
In these weeks, we delved into the Q-learning algorithm, a model-free, off-policy, value-based approach at the core of reinforcement learning. Additionally, we explored its variant, the deep Q-learning network, which replaces the Q table with a neural network. The final project involved training a deep Q network to master the game "Kung Fu Master" in the OpenAI Gym environment. You can find my implementation [here](https://github.com/Mehul-Agrawal410/AgentJackie_WiDS_2023/blob/main/final.py). Due to the game's complexity, a demo video showcasing improvement over the full training period is pending. The current implementation is trained for 30 episodes out of the intended 300.

**Resources**:
- [Intro to Q-learning - DataCamp](https://www.datacamp.com/tutorial/introduction-q-learning-beginner-tutorial)
- [Deep Q Learning Explanation](https://towardsdatascience.com/deep-q-learning-tutorial-mindqn-2a4c855abffc)
- [DQN Algorithm](https://towardsdatascience.com/reinforcement-learning-explained-visually-part-5-deep-q-networks-step-by-step-5a5317197f4b)

### Acknowledgement:
I extend my gratitude to the Analytics Club IIT Bombay for organizing WiDS, and special thanks to my mentors Nahush and Spandan for providing resources, assignments, and invaluable guidance throughout this rewarding journey.
